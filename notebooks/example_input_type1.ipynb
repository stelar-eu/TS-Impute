{
 "cells": [
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import stelarImputation as tsi"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-18T12:58:09.429774Z",
     "start_time": "2024-04-18T12:58:07.773307Z"
    }
   },
   "id": "7d06e22ee8dfb7bd",
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Gap Generation"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "deb58fa26858ef5a"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "df_input = '../datasets/example_input_type1.csv'\n",
    "\n",
    "parameters = {\n",
    "    'dimension_column' : 'Dimension',\n",
    "    'datetime_format' : '%Y-%m-%d %H:%M:%S',\n",
    "    'spatial_x_column': 'Spatial_X',\n",
    "    'spatial_y_column' : 'Spatial_Y',\n",
    "    'sep' : ',',\n",
    "    'header' : 0,\n",
    "    'preprocessing': True,\n",
    "    'index': False,\n",
    "    'train_params': {\n",
    "        \"gap_type\": \"no_overlap\",\n",
    "        \"miss_perc\": 0.1,\n",
    "        \"gap_length\": 100,\n",
    "        \"max_gap_length\": 10,\n",
    "        \"max_gap_count\": 5\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "dimension_column = parameters['dimension_column']\n",
    "header = parameters['header']\n",
    "sep = parameters['sep']\n",
    "spatial_x_column = parameters['spatial_x_column']\n",
    "spatial_y_column = parameters['spatial_y_column']\n",
    "datetime_format = parameters['datetime_format']\n",
    "preprocessing = parameters['preprocessing']\n",
    "index = parameters['index']\n",
    "train_params = parameters['train_params']"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-18T12:58:09.434709Z",
     "start_time": "2024-04-18T12:58:09.430988Z"
    }
   },
   "id": "88fa2ad58b835c1e",
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values count: 480\n"
     ]
    },
    {
     "data": {
      "text/plain": "                            Dimension  Spatial_X  Spatial_Y  \\\n0                 3i Group PLC_035999         96          0   \n1                Admiral Group_036346         97          1   \n2           Anglo American PLC_035918         98          2   \n3              Antofagasta PLC_028149         99          3   \n4                Ashtead Group_028090        100          4   \n..                                ...        ...        ...   \n91                Unilever PLC_035922        187         91   \n92  United Utilities Group PLC_036341        188         92   \n93          Vodafone Group PLC_035943        189         93   \n94               Whitbread PLC_035895        190         94   \n95                     WPP PLC_035947        191         95   \n\n    2017-01-02 00:00:00  2017-01-03 00:00:00  2017-01-04 00:00:00  \\\n0                   NaN                  NaN                  NaN   \n1             -1.347635            -1.189826            -1.325091   \n2             -1.294240            -1.286110            -1.365373   \n3             -2.295047            -2.136391            -2.120526   \n4             -1.199292            -1.136860            -1.155222   \n..                  ...                  ...                  ...   \n91            -2.869013            -2.931364            -2.886828   \n92             0.733771             0.710001             0.638689   \n93            -0.007477             0.100982             0.241340   \n94            -0.898946            -0.881773            -0.713477   \n95             1.592327             1.624480             1.578037   \n\n    2017-01-05 00:00:00  2017-01-06 00:00:00  2017-01-09 00:00:00  \\\n0                   NaN                  NaN            -1.887600   \n1             -1.336363            -1.313819                  NaN   \n2             -1.355211            -1.395858            -1.316596   \n3             -2.035909            -2.094083            -1.988312   \n4             -1.122170            -1.155222            -1.188275   \n..                  ...                  ...                  ...   \n91            -2.845854            -2.863669            -2.683742   \n92             0.724263             0.695738             0.705247   \n93             0.400838             0.481651             0.337039   \n94            -0.469618            -0.332233            -0.593265   \n95             1.642343             1.678069             1.767384   \n\n    2017-01-10 00:00:00  ...  2018-12-18 00:00:00  2018-12-19 00:00:00  \\\n0             -2.004563  ...            -1.356960            -1.273239   \n1                   NaN  ...             0.129009             0.151553   \n2             -0.979221  ...             0.951131             1.116160   \n3             -1.787348  ...            -1.290226            -1.120993   \n4             -1.122170  ...            -0.920183            -0.918347   \n..                  ...  ...                  ...                  ...   \n91            -2.717589  ...             0.399962             0.417777   \n92             0.633935  ...            -0.762826            -0.705777   \n93             0.434864  ...            -1.793430            -1.725377   \n94             0.045575  ...             1.405687             1.467510   \n95             1.813828  ...            -1.785209            -1.708041   \n\n    2018-12-20 00:00:00  2018-12-21 00:00:00  2018-12-24 00:00:00  \\\n0             -1.297863            -1.098411            -1.509627   \n1              0.326270             0.343178             0.405175   \n2              0.913735             1.110469             1.060066   \n3             -1.427728            -1.300803            -1.271187   \n4             -1.098299            -1.120334            -0.967925   \n..                  ...                  ...                  ...   \n91             0.378584             0.373240             0.237849   \n92            -0.606891            -0.519415            -0.878827   \n93            -1.704111            -1.841067            -1.936340   \n94             1.481249             1.453772             1.656414   \n95            -1.798785            -1.805216            -1.858805   \n\n    2018-12-25 00:00:00  2018-12-26 00:00:00  2018-12-27 00:00:00  \\\n0             -1.509627            -1.509627            -1.310175   \n1              0.405175             0.405175             0.433355   \n2              1.060066             1.060066             0.958448   \n3             -1.271187            -1.271187            -1.406574   \n4             -0.967925            -0.967925            -1.175421   \n..                  ...                  ...                  ...   \n91             0.237849             0.237849            -0.063217   \n92            -0.878827            -0.878827            -1.002434   \n93            -1.936340            -1.936340            -2.063088   \n94             1.656414             1.656414             1.501856   \n95            -1.858805            -1.858805            -1.929542   \n\n    2018-12-28 00:00:00  2018-12-31 00:00:00  \n0             -1.027002            -1.297863  \n1              0.861694             1.132225  \n2              1.121038             1.095023  \n3             -1.173878            -1.150609  \n4             -0.978943            -0.989960  \n..                  ...                  ...  \n91             0.097114             0.038326  \n92            -0.802761            -0.833187  \n93            -1.932938            -2.004393  \n94             1.766322             1.859057  \n95            -1.848087            -1.870951  \n\n[96 rows x 524 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Dimension</th>\n      <th>Spatial_X</th>\n      <th>Spatial_Y</th>\n      <th>2017-01-02 00:00:00</th>\n      <th>2017-01-03 00:00:00</th>\n      <th>2017-01-04 00:00:00</th>\n      <th>2017-01-05 00:00:00</th>\n      <th>2017-01-06 00:00:00</th>\n      <th>2017-01-09 00:00:00</th>\n      <th>2017-01-10 00:00:00</th>\n      <th>...</th>\n      <th>2018-12-18 00:00:00</th>\n      <th>2018-12-19 00:00:00</th>\n      <th>2018-12-20 00:00:00</th>\n      <th>2018-12-21 00:00:00</th>\n      <th>2018-12-24 00:00:00</th>\n      <th>2018-12-25 00:00:00</th>\n      <th>2018-12-26 00:00:00</th>\n      <th>2018-12-27 00:00:00</th>\n      <th>2018-12-28 00:00:00</th>\n      <th>2018-12-31 00:00:00</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>3i Group PLC_035999</td>\n      <td>96</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>-1.887600</td>\n      <td>-2.004563</td>\n      <td>...</td>\n      <td>-1.356960</td>\n      <td>-1.273239</td>\n      <td>-1.297863</td>\n      <td>-1.098411</td>\n      <td>-1.509627</td>\n      <td>-1.509627</td>\n      <td>-1.509627</td>\n      <td>-1.310175</td>\n      <td>-1.027002</td>\n      <td>-1.297863</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Admiral Group_036346</td>\n      <td>97</td>\n      <td>1</td>\n      <td>-1.347635</td>\n      <td>-1.189826</td>\n      <td>-1.325091</td>\n      <td>-1.336363</td>\n      <td>-1.313819</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>0.129009</td>\n      <td>0.151553</td>\n      <td>0.326270</td>\n      <td>0.343178</td>\n      <td>0.405175</td>\n      <td>0.405175</td>\n      <td>0.405175</td>\n      <td>0.433355</td>\n      <td>0.861694</td>\n      <td>1.132225</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Anglo American PLC_035918</td>\n      <td>98</td>\n      <td>2</td>\n      <td>-1.294240</td>\n      <td>-1.286110</td>\n      <td>-1.365373</td>\n      <td>-1.355211</td>\n      <td>-1.395858</td>\n      <td>-1.316596</td>\n      <td>-0.979221</td>\n      <td>...</td>\n      <td>0.951131</td>\n      <td>1.116160</td>\n      <td>0.913735</td>\n      <td>1.110469</td>\n      <td>1.060066</td>\n      <td>1.060066</td>\n      <td>1.060066</td>\n      <td>0.958448</td>\n      <td>1.121038</td>\n      <td>1.095023</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Antofagasta PLC_028149</td>\n      <td>99</td>\n      <td>3</td>\n      <td>-2.295047</td>\n      <td>-2.136391</td>\n      <td>-2.120526</td>\n      <td>-2.035909</td>\n      <td>-2.094083</td>\n      <td>-1.988312</td>\n      <td>-1.787348</td>\n      <td>...</td>\n      <td>-1.290226</td>\n      <td>-1.120993</td>\n      <td>-1.427728</td>\n      <td>-1.300803</td>\n      <td>-1.271187</td>\n      <td>-1.271187</td>\n      <td>-1.271187</td>\n      <td>-1.406574</td>\n      <td>-1.173878</td>\n      <td>-1.150609</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Ashtead Group_028090</td>\n      <td>100</td>\n      <td>4</td>\n      <td>-1.199292</td>\n      <td>-1.136860</td>\n      <td>-1.155222</td>\n      <td>-1.122170</td>\n      <td>-1.155222</td>\n      <td>-1.188275</td>\n      <td>-1.122170</td>\n      <td>...</td>\n      <td>-0.920183</td>\n      <td>-0.918347</td>\n      <td>-1.098299</td>\n      <td>-1.120334</td>\n      <td>-0.967925</td>\n      <td>-0.967925</td>\n      <td>-0.967925</td>\n      <td>-1.175421</td>\n      <td>-0.978943</td>\n      <td>-0.989960</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>91</th>\n      <td>Unilever PLC_035922</td>\n      <td>187</td>\n      <td>91</td>\n      <td>-2.869013</td>\n      <td>-2.931364</td>\n      <td>-2.886828</td>\n      <td>-2.845854</td>\n      <td>-2.863669</td>\n      <td>-2.683742</td>\n      <td>-2.717589</td>\n      <td>...</td>\n      <td>0.399962</td>\n      <td>0.417777</td>\n      <td>0.378584</td>\n      <td>0.373240</td>\n      <td>0.237849</td>\n      <td>0.237849</td>\n      <td>0.237849</td>\n      <td>-0.063217</td>\n      <td>0.097114</td>\n      <td>0.038326</td>\n    </tr>\n    <tr>\n      <th>92</th>\n      <td>United Utilities Group PLC_036341</td>\n      <td>188</td>\n      <td>92</td>\n      <td>0.733771</td>\n      <td>0.710001</td>\n      <td>0.638689</td>\n      <td>0.724263</td>\n      <td>0.695738</td>\n      <td>0.705247</td>\n      <td>0.633935</td>\n      <td>...</td>\n      <td>-0.762826</td>\n      <td>-0.705777</td>\n      <td>-0.606891</td>\n      <td>-0.519415</td>\n      <td>-0.878827</td>\n      <td>-0.878827</td>\n      <td>-0.878827</td>\n      <td>-1.002434</td>\n      <td>-0.802761</td>\n      <td>-0.833187</td>\n    </tr>\n    <tr>\n      <th>93</th>\n      <td>Vodafone Group PLC_035943</td>\n      <td>189</td>\n      <td>93</td>\n      <td>-0.007477</td>\n      <td>0.100982</td>\n      <td>0.241340</td>\n      <td>0.400838</td>\n      <td>0.481651</td>\n      <td>0.337039</td>\n      <td>0.434864</td>\n      <td>...</td>\n      <td>-1.793430</td>\n      <td>-1.725377</td>\n      <td>-1.704111</td>\n      <td>-1.841067</td>\n      <td>-1.936340</td>\n      <td>-1.936340</td>\n      <td>-1.936340</td>\n      <td>-2.063088</td>\n      <td>-1.932938</td>\n      <td>-2.004393</td>\n    </tr>\n    <tr>\n      <th>94</th>\n      <td>Whitbread PLC_035895</td>\n      <td>190</td>\n      <td>94</td>\n      <td>-0.898946</td>\n      <td>-0.881773</td>\n      <td>-0.713477</td>\n      <td>-0.469618</td>\n      <td>-0.332233</td>\n      <td>-0.593265</td>\n      <td>0.045575</td>\n      <td>...</td>\n      <td>1.405687</td>\n      <td>1.467510</td>\n      <td>1.481249</td>\n      <td>1.453772</td>\n      <td>1.656414</td>\n      <td>1.656414</td>\n      <td>1.656414</td>\n      <td>1.501856</td>\n      <td>1.766322</td>\n      <td>1.859057</td>\n    </tr>\n    <tr>\n      <th>95</th>\n      <td>WPP PLC_035947</td>\n      <td>191</td>\n      <td>95</td>\n      <td>1.592327</td>\n      <td>1.624480</td>\n      <td>1.578037</td>\n      <td>1.642343</td>\n      <td>1.678069</td>\n      <td>1.767384</td>\n      <td>1.813828</td>\n      <td>...</td>\n      <td>-1.785209</td>\n      <td>-1.708041</td>\n      <td>-1.798785</td>\n      <td>-1.805216</td>\n      <td>-1.858805</td>\n      <td>-1.858805</td>\n      <td>-1.858805</td>\n      <td>-1.929542</td>\n      <td>-1.848087</td>\n      <td>-1.870951</td>\n    </tr>\n  </tbody>\n</table>\n<p>96 rows × 524 columns</p>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_missing = tsi.run_gap_generation(ground_truth=df_input, \n",
    "                                    train_params=train_params, \n",
    "                                    dimension_column=dimension_column, \n",
    "                                    datetime_format=datetime_format, \n",
    "                                    spatial_x_column=spatial_x_column, \n",
    "                                    spatial_y_column=spatial_y_column, \n",
    "                                    header=header, \n",
    "                                    sep=sep, \n",
    "                                    preprocessing=preprocessing, \n",
    "                                    index=index)\n",
    "\n",
    "missing = df_missing.isnull().sum().sum()\n",
    "print(f\"Missing values count: {missing}\")\n",
    "df_missing"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-18T12:58:09.491963Z",
     "start_time": "2024-04-18T12:58:09.436075Z"
    }
   },
   "id": "658dfb14d4145728",
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Imputation"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c06dd72064d4e510"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "parameters = {\n",
    "    'dimension_column' : 'Dimension',\n",
    "    'datetime_format' : '%Y-%m-%d %H:%M:%S',\n",
    "    'spatial_x_column': 'Spatial_X',\n",
    "    'spatial_y_column' : 'Spatial_Y',\n",
    "    'sep' : ',',\n",
    "    'header' : 0,\n",
    "    'is_multivariate': False,\n",
    "    'areaVStime': 0,\n",
    "    'preprocessing': True,\n",
    "    'index': False,\n",
    "    \"algorithms\": [\"SoftImpute\", \"IterativeSVD\", \"SVT\", \"TimesNet\"],\n",
    "    \"params\": { \n",
    "        \"SoftImpute\": { \"max_rank\": 5 },\n",
    "        \"IterativeSVD\": { \"rank\": 3 }, \n",
    "        \"SVT\": { \"tauScale\": 0.7}, \n",
    "        \"TimesNet\":{ \n",
    "            \"n_layers\": 2, \"top_k\": 3, \n",
    "            \"d_model\":56, \"d_ffn\":56, \n",
    "            \"n_kernels\":1, \"dropout\":0.05, \n",
    "            \"apply_nonstationary_norm\": False,\n",
    "            \"batch_size\": 32,\n",
    "            \"epochs\":50,\n",
    "            \"num_workers\": 0                                                        \n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "dimension_column = parameters['dimension_column']\n",
    "header = parameters['header']\n",
    "sep = parameters['sep']\n",
    "spatial_x_column = parameters['spatial_x_column']\n",
    "spatial_y_column = parameters['spatial_y_column']\n",
    "datetime_format = parameters['datetime_format']\n",
    "is_multivariate = parameters['is_multivariate']\n",
    "areaVStime = parameters['areaVStime']\n",
    "preprocessing = parameters['preprocessing']\n",
    "index = parameters['index']\n",
    "algorithms = parameters['algorithms']\n",
    "params = parameters['params']"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-18T12:58:09.497177Z",
     "start_time": "2024-04-18T12:58:09.493149Z"
    }
   },
   "id": "eab173986d693e6b",
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "freeing copy memory @ 0x8890a20\n",
      "freeing copy memory @ 0x8798100\n",
      "freeing copy memory @ 0x89bbf80\n",
      "2024-04-18 15:58:15 [INFO]: No given device, using default device: cuda\n",
      "2024-04-18 15:58:15 [WARNING]: ‼️ saving_path not given. Model files and tensorboard file will not be saved.\n",
      "2024-04-18 15:58:16 [INFO]: TimesNet initialized with the given hyperparameters, the number of trainable parameters: 13,105\n",
      "2024-04-18 15:58:16 [INFO]: Epoch 001 - training loss: 0.5469\n",
      "2024-04-18 15:58:16 [INFO]: Epoch 002 - training loss: 0.3120\n",
      "2024-04-18 15:58:16 [INFO]: Epoch 003 - training loss: 0.3056\n",
      "2024-04-18 15:58:16 [INFO]: Epoch 004 - training loss: 0.2839\n",
      "2024-04-18 15:58:16 [INFO]: Epoch 005 - training loss: 0.2314\n",
      "2024-04-18 15:58:16 [INFO]: Epoch 006 - training loss: 0.2028\n",
      "2024-04-18 15:58:16 [INFO]: Epoch 007 - training loss: 0.1999\n",
      "2024-04-18 15:58:16 [INFO]: Epoch 008 - training loss: 0.1892\n",
      "2024-04-18 15:58:16 [INFO]: Epoch 009 - training loss: 0.1705\n",
      "2024-04-18 15:58:16 [INFO]: Epoch 010 - training loss: 0.1595\n",
      "2024-04-18 15:58:16 [INFO]: Epoch 011 - training loss: 0.1528\n",
      "2024-04-18 15:58:16 [INFO]: Epoch 012 - training loss: 0.1539\n",
      "2024-04-18 15:58:16 [INFO]: Epoch 013 - training loss: 0.1404\n",
      "2024-04-18 15:58:16 [INFO]: Epoch 014 - training loss: 0.1468\n",
      "2024-04-18 15:58:17 [INFO]: Epoch 015 - training loss: 0.1340\n",
      "2024-04-18 15:58:17 [INFO]: Epoch 016 - training loss: 0.1322\n",
      "2024-04-18 15:58:17 [INFO]: Epoch 017 - training loss: 0.1292\n",
      "2024-04-18 15:58:17 [INFO]: Epoch 018 - training loss: 0.1216\n",
      "2024-04-18 15:58:17 [INFO]: Epoch 019 - training loss: 0.1200\n",
      "2024-04-18 15:58:17 [INFO]: Epoch 020 - training loss: 0.1201\n",
      "2024-04-18 15:58:17 [INFO]: Epoch 021 - training loss: 0.1135\n",
      "2024-04-18 15:58:17 [INFO]: Epoch 022 - training loss: 0.1098\n",
      "2024-04-18 15:58:17 [INFO]: Epoch 023 - training loss: 0.1146\n",
      "2024-04-18 15:58:17 [INFO]: Epoch 024 - training loss: 0.1106\n",
      "2024-04-18 15:58:17 [INFO]: Epoch 025 - training loss: 0.1064\n",
      "2024-04-18 15:58:17 [INFO]: Epoch 026 - training loss: 0.0981\n",
      "2024-04-18 15:58:17 [INFO]: Epoch 027 - training loss: 0.1042\n",
      "2024-04-18 15:58:17 [INFO]: Epoch 028 - training loss: 0.0971\n",
      "2024-04-18 15:58:17 [INFO]: Epoch 029 - training loss: 0.0976\n",
      "2024-04-18 15:58:17 [INFO]: Epoch 030 - training loss: 0.0888\n",
      "2024-04-18 15:58:17 [INFO]: Epoch 031 - training loss: 0.0962\n",
      "2024-04-18 15:58:17 [INFO]: Epoch 032 - training loss: 0.0992\n",
      "2024-04-18 15:58:17 [INFO]: Epoch 033 - training loss: 0.0889\n",
      "2024-04-18 15:58:17 [INFO]: Epoch 034 - training loss: 0.0884\n",
      "2024-04-18 15:58:17 [INFO]: Epoch 035 - training loss: 0.0914\n",
      "2024-04-18 15:58:17 [INFO]: Epoch 036 - training loss: 0.0928\n",
      "2024-04-18 15:58:17 [INFO]: Epoch 037 - training loss: 0.0887\n",
      "2024-04-18 15:58:17 [INFO]: Epoch 038 - training loss: 0.0830\n",
      "2024-04-18 15:58:17 [INFO]: Epoch 039 - training loss: 0.0897\n",
      "2024-04-18 15:58:18 [INFO]: Epoch 040 - training loss: 0.0898\n",
      "2024-04-18 15:58:18 [INFO]: Epoch 041 - training loss: 0.0852\n",
      "2024-04-18 15:58:18 [INFO]: Epoch 042 - training loss: 0.0811\n",
      "2024-04-18 15:58:18 [INFO]: Epoch 043 - training loss: 0.0878\n",
      "2024-04-18 15:58:18 [INFO]: Epoch 044 - training loss: 0.0838\n",
      "2024-04-18 15:58:18 [INFO]: Epoch 045 - training loss: 0.0865\n",
      "2024-04-18 15:58:18 [INFO]: Epoch 046 - training loss: 0.0807\n",
      "2024-04-18 15:58:18 [INFO]: Epoch 047 - training loss: 0.0924\n",
      "2024-04-18 15:58:18 [INFO]: Epoch 048 - training loss: 0.0796\n",
      "2024-04-18 15:58:18 [INFO]: Epoch 049 - training loss: 0.0899\n",
      "2024-04-18 15:58:18 [INFO]: Epoch 050 - training loss: 0.0782\n",
      "2024-04-18 15:58:18 [INFO]: Finished training.\n"
     ]
    }
   ],
   "source": [
    "dict_of_imputed_dfs = tsi.run_imputation(missing = df_missing, \n",
    "                                         algorithms=algorithms, \n",
    "                                         params=params, \n",
    "                                         dimension_column=dimension_column,\n",
    "                                         datetime_format=datetime_format, \n",
    "                                         spatial_x_column=spatial_x_column,\n",
    "                                         spatial_y_column=spatial_y_column, \n",
    "                                         header=header, \n",
    "                                         sep=sep, \n",
    "                                         is_multivariate=is_multivariate, \n",
    "                                         areaVStime=areaVStime, \n",
    "                                         preprocessing=preprocessing, \n",
    "                                         index=index)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-18T12:58:18.456838Z",
     "start_time": "2024-04-18T12:58:09.499208Z"
    }
   },
   "id": "bf4f82d7f54c335f",
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values count: 0\n"
     ]
    },
    {
     "data": {
      "text/plain": "                            Dimension  Spatial_X  Spatial_Y  \\\n0                 3i Group PLC_035999         96          0   \n1                Admiral Group_036346         97          1   \n2           Anglo American PLC_035918         98          2   \n3              Antofagasta PLC_028149         99          3   \n4                Ashtead Group_028090        100          4   \n..                                ...        ...        ...   \n91                Unilever PLC_035922        187         91   \n92  United Utilities Group PLC_036341        188         92   \n93          Vodafone Group PLC_035943        189         93   \n94               Whitbread PLC_035895        190         94   \n95                     WPP PLC_035947        191         95   \n\n    2017-01-02 00:00:00  2017-01-03 00:00:00  2017-01-04 00:00:00  \\\n0             -2.603107            -2.581500            -2.526286   \n1             -1.347635            -1.189826            -1.325091   \n2             -1.294240            -1.286110            -1.365373   \n3             -2.295047            -2.136391            -2.120526   \n4             -1.199292            -1.136860            -1.155222   \n..                  ...                  ...                  ...   \n91            -2.869013            -2.931364            -2.886828   \n92             0.733771             0.710001             0.638689   \n93            -0.007477             0.100982             0.241340   \n94            -0.898946            -0.881773            -0.713477   \n95             1.592327             1.624480             1.578037   \n\n    2017-01-05 00:00:00  2017-01-06 00:00:00  2017-01-09 00:00:00  \\\n0             -2.510187            -2.494425            -1.887600   \n1             -1.336363            -1.313819            -1.308421   \n2             -1.355211            -1.395858            -1.316596   \n3             -2.035909            -2.094083            -1.988312   \n4             -1.122170            -1.155222            -1.188275   \n..                  ...                  ...                  ...   \n91            -2.845854            -2.863669            -2.683742   \n92             0.724263             0.695738             0.705247   \n93             0.400838             0.481651             0.337039   \n94            -0.469618            -0.332233            -0.593265   \n95             1.642343             1.678069             1.767384   \n\n    2017-01-10 00:00:00  ...  2018-12-18 00:00:00  2018-12-19 00:00:00  \\\n0             -2.004563  ...            -1.356960            -1.273239   \n1             -1.268704  ...             0.129009             0.151553   \n2             -0.979221  ...             0.951131             1.116160   \n3             -1.787348  ...            -1.290226            -1.120993   \n4             -1.122170  ...            -0.920183            -0.918347   \n..                  ...  ...                  ...                  ...   \n91            -2.717589  ...             0.399962             0.417777   \n92             0.633935  ...            -0.762826            -0.705777   \n93             0.434864  ...            -1.793430            -1.725377   \n94             0.045575  ...             1.405687             1.467510   \n95             1.813828  ...            -1.785209            -1.708041   \n\n    2018-12-20 00:00:00  2018-12-21 00:00:00  2018-12-24 00:00:00  \\\n0             -1.297863            -1.098411            -1.509627   \n1              0.326270             0.343178             0.405175   \n2              0.913735             1.110469             1.060066   \n3             -1.427728            -1.300803            -1.271187   \n4             -1.098299            -1.120334            -0.967925   \n..                  ...                  ...                  ...   \n91             0.378584             0.373240             0.237849   \n92            -0.606891            -0.519415            -0.878827   \n93            -1.704111            -1.841067            -1.936340   \n94             1.481249             1.453772             1.656414   \n95            -1.798785            -1.805216            -1.858805   \n\n    2018-12-25 00:00:00  2018-12-26 00:00:00  2018-12-27 00:00:00  \\\n0             -1.509627            -1.509627            -1.310175   \n1              0.405175             0.405175             0.433355   \n2              1.060066             1.060066             0.958448   \n3             -1.271187            -1.271187            -1.406574   \n4             -0.967925            -0.967925            -1.175421   \n..                  ...                  ...                  ...   \n91             0.237849             0.237849            -0.063217   \n92            -0.878827            -0.878827            -1.002434   \n93            -1.936340            -1.936340            -2.063088   \n94             1.656414             1.656414             1.501856   \n95            -1.858805            -1.858805            -1.929542   \n\n    2018-12-28 00:00:00  2018-12-31 00:00:00  \n0             -1.027002            -1.297863  \n1              0.861694             1.132225  \n2              1.121038             1.095023  \n3             -1.173878            -1.150609  \n4             -0.978943            -0.989960  \n..                  ...                  ...  \n91             0.097114             0.038326  \n92            -0.802761            -0.833187  \n93            -1.932938            -2.004393  \n94             1.766322             1.859057  \n95            -1.848087            -1.870951  \n\n[96 rows x 524 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Dimension</th>\n      <th>Spatial_X</th>\n      <th>Spatial_Y</th>\n      <th>2017-01-02 00:00:00</th>\n      <th>2017-01-03 00:00:00</th>\n      <th>2017-01-04 00:00:00</th>\n      <th>2017-01-05 00:00:00</th>\n      <th>2017-01-06 00:00:00</th>\n      <th>2017-01-09 00:00:00</th>\n      <th>2017-01-10 00:00:00</th>\n      <th>...</th>\n      <th>2018-12-18 00:00:00</th>\n      <th>2018-12-19 00:00:00</th>\n      <th>2018-12-20 00:00:00</th>\n      <th>2018-12-21 00:00:00</th>\n      <th>2018-12-24 00:00:00</th>\n      <th>2018-12-25 00:00:00</th>\n      <th>2018-12-26 00:00:00</th>\n      <th>2018-12-27 00:00:00</th>\n      <th>2018-12-28 00:00:00</th>\n      <th>2018-12-31 00:00:00</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>3i Group PLC_035999</td>\n      <td>96</td>\n      <td>0</td>\n      <td>-2.603107</td>\n      <td>-2.581500</td>\n      <td>-2.526286</td>\n      <td>-2.510187</td>\n      <td>-2.494425</td>\n      <td>-1.887600</td>\n      <td>-2.004563</td>\n      <td>...</td>\n      <td>-1.356960</td>\n      <td>-1.273239</td>\n      <td>-1.297863</td>\n      <td>-1.098411</td>\n      <td>-1.509627</td>\n      <td>-1.509627</td>\n      <td>-1.509627</td>\n      <td>-1.310175</td>\n      <td>-1.027002</td>\n      <td>-1.297863</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Admiral Group_036346</td>\n      <td>97</td>\n      <td>1</td>\n      <td>-1.347635</td>\n      <td>-1.189826</td>\n      <td>-1.325091</td>\n      <td>-1.336363</td>\n      <td>-1.313819</td>\n      <td>-1.308421</td>\n      <td>-1.268704</td>\n      <td>...</td>\n      <td>0.129009</td>\n      <td>0.151553</td>\n      <td>0.326270</td>\n      <td>0.343178</td>\n      <td>0.405175</td>\n      <td>0.405175</td>\n      <td>0.405175</td>\n      <td>0.433355</td>\n      <td>0.861694</td>\n      <td>1.132225</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Anglo American PLC_035918</td>\n      <td>98</td>\n      <td>2</td>\n      <td>-1.294240</td>\n      <td>-1.286110</td>\n      <td>-1.365373</td>\n      <td>-1.355211</td>\n      <td>-1.395858</td>\n      <td>-1.316596</td>\n      <td>-0.979221</td>\n      <td>...</td>\n      <td>0.951131</td>\n      <td>1.116160</td>\n      <td>0.913735</td>\n      <td>1.110469</td>\n      <td>1.060066</td>\n      <td>1.060066</td>\n      <td>1.060066</td>\n      <td>0.958448</td>\n      <td>1.121038</td>\n      <td>1.095023</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Antofagasta PLC_028149</td>\n      <td>99</td>\n      <td>3</td>\n      <td>-2.295047</td>\n      <td>-2.136391</td>\n      <td>-2.120526</td>\n      <td>-2.035909</td>\n      <td>-2.094083</td>\n      <td>-1.988312</td>\n      <td>-1.787348</td>\n      <td>...</td>\n      <td>-1.290226</td>\n      <td>-1.120993</td>\n      <td>-1.427728</td>\n      <td>-1.300803</td>\n      <td>-1.271187</td>\n      <td>-1.271187</td>\n      <td>-1.271187</td>\n      <td>-1.406574</td>\n      <td>-1.173878</td>\n      <td>-1.150609</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Ashtead Group_028090</td>\n      <td>100</td>\n      <td>4</td>\n      <td>-1.199292</td>\n      <td>-1.136860</td>\n      <td>-1.155222</td>\n      <td>-1.122170</td>\n      <td>-1.155222</td>\n      <td>-1.188275</td>\n      <td>-1.122170</td>\n      <td>...</td>\n      <td>-0.920183</td>\n      <td>-0.918347</td>\n      <td>-1.098299</td>\n      <td>-1.120334</td>\n      <td>-0.967925</td>\n      <td>-0.967925</td>\n      <td>-0.967925</td>\n      <td>-1.175421</td>\n      <td>-0.978943</td>\n      <td>-0.989960</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>91</th>\n      <td>Unilever PLC_035922</td>\n      <td>187</td>\n      <td>91</td>\n      <td>-2.869013</td>\n      <td>-2.931364</td>\n      <td>-2.886828</td>\n      <td>-2.845854</td>\n      <td>-2.863669</td>\n      <td>-2.683742</td>\n      <td>-2.717589</td>\n      <td>...</td>\n      <td>0.399962</td>\n      <td>0.417777</td>\n      <td>0.378584</td>\n      <td>0.373240</td>\n      <td>0.237849</td>\n      <td>0.237849</td>\n      <td>0.237849</td>\n      <td>-0.063217</td>\n      <td>0.097114</td>\n      <td>0.038326</td>\n    </tr>\n    <tr>\n      <th>92</th>\n      <td>United Utilities Group PLC_036341</td>\n      <td>188</td>\n      <td>92</td>\n      <td>0.733771</td>\n      <td>0.710001</td>\n      <td>0.638689</td>\n      <td>0.724263</td>\n      <td>0.695738</td>\n      <td>0.705247</td>\n      <td>0.633935</td>\n      <td>...</td>\n      <td>-0.762826</td>\n      <td>-0.705777</td>\n      <td>-0.606891</td>\n      <td>-0.519415</td>\n      <td>-0.878827</td>\n      <td>-0.878827</td>\n      <td>-0.878827</td>\n      <td>-1.002434</td>\n      <td>-0.802761</td>\n      <td>-0.833187</td>\n    </tr>\n    <tr>\n      <th>93</th>\n      <td>Vodafone Group PLC_035943</td>\n      <td>189</td>\n      <td>93</td>\n      <td>-0.007477</td>\n      <td>0.100982</td>\n      <td>0.241340</td>\n      <td>0.400838</td>\n      <td>0.481651</td>\n      <td>0.337039</td>\n      <td>0.434864</td>\n      <td>...</td>\n      <td>-1.793430</td>\n      <td>-1.725377</td>\n      <td>-1.704111</td>\n      <td>-1.841067</td>\n      <td>-1.936340</td>\n      <td>-1.936340</td>\n      <td>-1.936340</td>\n      <td>-2.063088</td>\n      <td>-1.932938</td>\n      <td>-2.004393</td>\n    </tr>\n    <tr>\n      <th>94</th>\n      <td>Whitbread PLC_035895</td>\n      <td>190</td>\n      <td>94</td>\n      <td>-0.898946</td>\n      <td>-0.881773</td>\n      <td>-0.713477</td>\n      <td>-0.469618</td>\n      <td>-0.332233</td>\n      <td>-0.593265</td>\n      <td>0.045575</td>\n      <td>...</td>\n      <td>1.405687</td>\n      <td>1.467510</td>\n      <td>1.481249</td>\n      <td>1.453772</td>\n      <td>1.656414</td>\n      <td>1.656414</td>\n      <td>1.656414</td>\n      <td>1.501856</td>\n      <td>1.766322</td>\n      <td>1.859057</td>\n    </tr>\n    <tr>\n      <th>95</th>\n      <td>WPP PLC_035947</td>\n      <td>191</td>\n      <td>95</td>\n      <td>1.592327</td>\n      <td>1.624480</td>\n      <td>1.578037</td>\n      <td>1.642343</td>\n      <td>1.678069</td>\n      <td>1.767384</td>\n      <td>1.813828</td>\n      <td>...</td>\n      <td>-1.785209</td>\n      <td>-1.708041</td>\n      <td>-1.798785</td>\n      <td>-1.805216</td>\n      <td>-1.858805</td>\n      <td>-1.858805</td>\n      <td>-1.858805</td>\n      <td>-1.929542</td>\n      <td>-1.848087</td>\n      <td>-1.870951</td>\n    </tr>\n  </tbody>\n</table>\n<p>96 rows × 524 columns</p>\n</div>"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imputed_df =dict_of_imputed_dfs['SoftImpute']\n",
    "missing = imputed_df.isnull().sum().sum()\n",
    "print(f\"Missing values count: {missing}\")\n",
    "imputed_df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-18T12:58:18.470917Z",
     "start_time": "2024-04-18T12:58:18.458277Z"
    }
   },
   "id": "43857f333cf8cfd9",
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Train Ensemble Model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "851d34f0bc65c4b"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "parameters = {\n",
    "    'dimension_column' : 'Dimension',\n",
    "    'datetime_format' : '%Y-%m-%d %H:%M:%S',\n",
    "    'spatial_x_column': 'Spatial_X',\n",
    "    'spatial_y_column' : 'Spatial_Y',\n",
    "    'sep' : ',',\n",
    "    'header' : 0,\n",
    "    'is_multivariate': False,\n",
    "    'areaVStime': 0,\n",
    "    'preprocessing': True,\n",
    "    'index': False,\n",
    "    \"algorithms\": [\"SoftImpute\", \"IterativeSVD\", \"SVT\", \"TimesNet\"],\n",
    "    \"params\": { \n",
    "        \"SoftImpute\": { \"max_rank\": 5 },\n",
    "        \"IterativeSVD\": { \"rank\": 3 }, \n",
    "        \"SVT\": { \"tauScale\": 0.7}, \n",
    "        \"TimesNet\":{ \n",
    "            \"n_layers\": 2, \"top_k\": 3, \n",
    "            \"d_model\":56, \"d_ffn\":56, \n",
    "            \"n_kernels\":1, \"dropout\":0.05, \n",
    "            \"apply_nonstationary_norm\": False,\n",
    "            \"batch_size\": 32,\n",
    "            \"epochs\":50,\n",
    "            \"num_workers\": 0                                                        \n",
    "        }\n",
    "    },\n",
    "    'train_params': {\n",
    "        \"smooth\": False,\n",
    "        \"window\": 2,\n",
    "        \"order\": 1,\n",
    "        \"normalize\": False,\n",
    "        \"gap_type\": \"no_overlap\",\n",
    "        \"miss_perc\": 0.1,\n",
    "        \"gap_length\": 100,\n",
    "        \"max_gap_length\": 10,\n",
    "        \"max_gap_count\": 5\n",
    "    }\n",
    "}\n",
    "\n",
    "dimension_column = parameters['dimension_column']\n",
    "header = parameters['header']\n",
    "sep = parameters['sep']\n",
    "spatial_x_column = parameters['spatial_x_column']\n",
    "spatial_y_column = parameters['spatial_y_column']\n",
    "datetime_format = parameters['datetime_format']\n",
    "is_multivariate = parameters['is_multivariate']\n",
    "areaVStime = parameters['areaVStime']\n",
    "preprocessing = parameters['preprocessing']\n",
    "index = parameters['index']\n",
    "algorithms = parameters['algorithms']\n",
    "params = parameters['params']\n",
    "train_params = parameters['train_params']"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-18T12:58:18.480709Z",
     "start_time": "2024-04-18T12:58:18.471930Z"
    }
   },
   "id": "c2c8104cca230c33",
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "freeing copy memory @ 0x1c9d5de0\n",
      "freeing copy memory @ 0x1c9d5de0\n",
      "freeing copy memory @ 0x1c9d5de0\n",
      "2024-04-18 15:58:26 [INFO]: No given device, using default device: cuda\n",
      "2024-04-18 15:58:26 [WARNING]: ‼️ saving_path not given. Model files and tensorboard file will not be saved.\n",
      "2024-04-18 15:58:26 [INFO]: TimesNet initialized with the given hyperparameters, the number of trainable parameters: 13,105\n",
      "2024-04-18 15:58:27 [INFO]: Epoch 001 - training loss: 0.8405\n",
      "2024-04-18 15:58:27 [INFO]: Epoch 002 - training loss: 0.3585\n",
      "2024-04-18 15:58:27 [INFO]: Epoch 003 - training loss: 0.3235\n",
      "2024-04-18 15:58:27 [INFO]: Epoch 004 - training loss: 0.3226\n",
      "2024-04-18 15:58:27 [INFO]: Epoch 005 - training loss: 0.2568\n",
      "2024-04-18 15:58:27 [INFO]: Epoch 006 - training loss: 0.2209\n",
      "2024-04-18 15:58:27 [INFO]: Epoch 007 - training loss: 0.2166\n",
      "2024-04-18 15:58:27 [INFO]: Epoch 008 - training loss: 0.2110\n",
      "2024-04-18 15:58:27 [INFO]: Epoch 009 - training loss: 0.1884\n",
      "2024-04-18 15:58:27 [INFO]: Epoch 010 - training loss: 0.1751\n",
      "2024-04-18 15:58:27 [INFO]: Epoch 011 - training loss: 0.1629\n",
      "2024-04-18 15:58:27 [INFO]: Epoch 012 - training loss: 0.1557\n",
      "2024-04-18 15:58:27 [INFO]: Epoch 013 - training loss: 0.1496\n",
      "2024-04-18 15:58:27 [INFO]: Epoch 014 - training loss: 0.1461\n",
      "2024-04-18 15:58:27 [INFO]: Epoch 015 - training loss: 0.1426\n",
      "2024-04-18 15:58:27 [INFO]: Epoch 016 - training loss: 0.1349\n",
      "2024-04-18 15:58:27 [INFO]: Epoch 017 - training loss: 0.1331\n",
      "2024-04-18 15:58:27 [INFO]: Epoch 018 - training loss: 0.1212\n",
      "2024-04-18 15:58:27 [INFO]: Epoch 019 - training loss: 0.1155\n",
      "2024-04-18 15:58:27 [INFO]: Epoch 020 - training loss: 0.1208\n",
      "2024-04-18 15:58:28 [INFO]: Epoch 021 - training loss: 0.1175\n",
      "2024-04-18 15:58:28 [INFO]: Epoch 022 - training loss: 0.1124\n",
      "2024-04-18 15:58:28 [INFO]: Epoch 023 - training loss: 0.1118\n",
      "2024-04-18 15:58:28 [INFO]: Epoch 024 - training loss: 0.1003\n",
      "2024-04-18 15:58:28 [INFO]: Epoch 025 - training loss: 0.1028\n",
      "2024-04-18 15:58:28 [INFO]: Epoch 026 - training loss: 0.1025\n",
      "2024-04-18 15:58:28 [INFO]: Epoch 027 - training loss: 0.1021\n",
      "2024-04-18 15:58:28 [INFO]: Epoch 028 - training loss: 0.1012\n",
      "2024-04-18 15:58:28 [INFO]: Epoch 029 - training loss: 0.0998\n",
      "2024-04-18 15:58:28 [INFO]: Epoch 030 - training loss: 0.1048\n",
      "2024-04-18 15:58:28 [INFO]: Epoch 031 - training loss: 0.0968\n",
      "2024-04-18 15:58:28 [INFO]: Epoch 032 - training loss: 0.1015\n",
      "2024-04-18 15:58:28 [INFO]: Epoch 033 - training loss: 0.0861\n",
      "2024-04-18 15:58:28 [INFO]: Epoch 034 - training loss: 0.0897\n",
      "2024-04-18 15:58:28 [INFO]: Epoch 035 - training loss: 0.0882\n",
      "2024-04-18 15:58:28 [INFO]: Epoch 036 - training loss: 0.0948\n",
      "2024-04-18 15:58:28 [INFO]: Epoch 037 - training loss: 0.0891\n",
      "2024-04-18 15:58:28 [INFO]: Epoch 038 - training loss: 0.0921\n",
      "2024-04-18 15:58:28 [INFO]: Epoch 039 - training loss: 0.0924\n",
      "2024-04-18 15:58:28 [INFO]: Epoch 040 - training loss: 0.0878\n",
      "2024-04-18 15:58:28 [INFO]: Epoch 041 - training loss: 0.0913\n",
      "2024-04-18 15:58:28 [INFO]: Epoch 042 - training loss: 0.0906\n",
      "2024-04-18 15:58:28 [INFO]: Epoch 043 - training loss: 0.0869\n",
      "2024-04-18 15:58:28 [INFO]: Epoch 044 - training loss: 0.0858\n",
      "2024-04-18 15:58:29 [INFO]: Epoch 045 - training loss: 0.0875\n",
      "2024-04-18 15:58:29 [INFO]: Epoch 046 - training loss: 0.0879\n",
      "2024-04-18 15:58:29 [INFO]: Epoch 047 - training loss: 0.0814\n",
      "2024-04-18 15:58:29 [INFO]: Epoch 048 - training loss: 0.0773\n",
      "2024-04-18 15:58:29 [INFO]: Epoch 049 - training loss: 0.0866\n",
      "2024-04-18 15:58:29 [INFO]: Epoch 050 - training loss: 0.0893\n",
      "2024-04-18 15:58:29 [INFO]: Finished training.\n",
      "freeing copy memory @ 0x1c9742a0\n",
      "freeing copy memory @ 0x1c9d5de0\n",
      "freeing copy memory @ 0x1c9d5de0\n",
      "2024-04-18 15:58:34 [INFO]: No given device, using default device: cuda\n",
      "2024-04-18 15:58:34 [WARNING]: ‼️ saving_path not given. Model files and tensorboard file will not be saved.\n",
      "2024-04-18 15:58:34 [INFO]: TimesNet initialized with the given hyperparameters, the number of trainable parameters: 13,105\n",
      "2024-04-18 15:58:34 [INFO]: Epoch 001 - training loss: 1.3964\n",
      "2024-04-18 15:58:35 [INFO]: Epoch 002 - training loss: 0.6663\n",
      "2024-04-18 15:58:35 [INFO]: Epoch 003 - training loss: 0.3399\n",
      "2024-04-18 15:58:35 [INFO]: Epoch 004 - training loss: 0.2848\n",
      "2024-04-18 15:58:35 [INFO]: Epoch 005 - training loss: 0.2986\n",
      "2024-04-18 15:58:35 [INFO]: Epoch 006 - training loss: 0.2920\n",
      "2024-04-18 15:58:35 [INFO]: Epoch 007 - training loss: 0.2543\n",
      "2024-04-18 15:58:35 [INFO]: Epoch 008 - training loss: 0.2191\n",
      "2024-04-18 15:58:35 [INFO]: Epoch 009 - training loss: 0.2118\n",
      "2024-04-18 15:58:35 [INFO]: Epoch 010 - training loss: 0.1950\n",
      "2024-04-18 15:58:35 [INFO]: Epoch 011 - training loss: 0.1868\n",
      "2024-04-18 15:58:35 [INFO]: Epoch 012 - training loss: 0.1891\n",
      "2024-04-18 15:58:35 [INFO]: Epoch 013 - training loss: 0.1674\n",
      "2024-04-18 15:58:35 [INFO]: Epoch 014 - training loss: 0.1689\n",
      "2024-04-18 15:58:35 [INFO]: Epoch 015 - training loss: 0.1538\n",
      "2024-04-18 15:58:35 [INFO]: Epoch 016 - training loss: 0.1590\n",
      "2024-04-18 15:58:35 [INFO]: Epoch 017 - training loss: 0.1465\n",
      "2024-04-18 15:58:35 [INFO]: Epoch 018 - training loss: 0.1437\n",
      "2024-04-18 15:58:35 [INFO]: Epoch 019 - training loss: 0.1426\n",
      "2024-04-18 15:58:35 [INFO]: Epoch 020 - training loss: 0.1409\n",
      "2024-04-18 15:58:35 [INFO]: Epoch 021 - training loss: 0.1309\n",
      "2024-04-18 15:58:35 [INFO]: Epoch 022 - training loss: 0.1294\n",
      "2024-04-18 15:58:35 [INFO]: Epoch 023 - training loss: 0.1290\n",
      "2024-04-18 15:58:35 [INFO]: Epoch 024 - training loss: 0.1284\n",
      "2024-04-18 15:58:35 [INFO]: Epoch 025 - training loss: 0.1238\n",
      "2024-04-18 15:58:36 [INFO]: Epoch 026 - training loss: 0.1201\n",
      "2024-04-18 15:58:36 [INFO]: Epoch 027 - training loss: 0.1229\n",
      "2024-04-18 15:58:36 [INFO]: Epoch 028 - training loss: 0.1174\n",
      "2024-04-18 15:58:36 [INFO]: Epoch 029 - training loss: 0.1217\n",
      "2024-04-18 15:58:36 [INFO]: Epoch 030 - training loss: 0.1079\n",
      "2024-04-18 15:58:36 [INFO]: Epoch 031 - training loss: 0.1022\n",
      "2024-04-18 15:58:36 [INFO]: Epoch 032 - training loss: 0.1173\n",
      "2024-04-18 15:58:36 [INFO]: Epoch 033 - training loss: 0.1107\n",
      "2024-04-18 15:58:36 [INFO]: Epoch 034 - training loss: 0.0988\n",
      "2024-04-18 15:58:36 [INFO]: Epoch 035 - training loss: 0.0998\n",
      "2024-04-18 15:58:36 [INFO]: Epoch 036 - training loss: 0.1108\n",
      "2024-04-18 15:58:36 [INFO]: Epoch 037 - training loss: 0.1073\n",
      "2024-04-18 15:58:36 [INFO]: Epoch 038 - training loss: 0.1026\n",
      "2024-04-18 15:58:36 [INFO]: Epoch 039 - training loss: 0.0958\n",
      "2024-04-18 15:58:36 [INFO]: Epoch 040 - training loss: 0.0928\n",
      "2024-04-18 15:58:36 [INFO]: Epoch 041 - training loss: 0.1000\n",
      "2024-04-18 15:58:36 [INFO]: Epoch 042 - training loss: 0.0922\n",
      "2024-04-18 15:58:36 [INFO]: Epoch 043 - training loss: 0.0900\n",
      "2024-04-18 15:58:36 [INFO]: Epoch 044 - training loss: 0.0964\n",
      "2024-04-18 15:58:36 [INFO]: Epoch 045 - training loss: 0.0929\n",
      "2024-04-18 15:58:36 [INFO]: Epoch 046 - training loss: 0.0877\n",
      "2024-04-18 15:58:36 [INFO]: Epoch 047 - training loss: 0.0884\n",
      "2024-04-18 15:58:36 [INFO]: Epoch 048 - training loss: 0.0864\n",
      "2024-04-18 15:58:36 [INFO]: Epoch 049 - training loss: 0.0884\n",
      "2024-04-18 15:58:36 [INFO]: Epoch 050 - training loss: 0.0842\n",
      "2024-04-18 15:58:36 [INFO]: Finished training.\n"
     ]
    },
    {
     "data": {
      "text/plain": "{'SoftImpute': {'mae': 0.3219266070325954,\n  'mse': 0.18658043936819813,\n  'rmse': 0.43194957965970765,\n  'r2': 0.792064301449704,\n  'euclidean_distance': 207.3357982366597},\n 'IterativeSVD': {'mae': 0.42643071248629255,\n  'mse': 0.29755081878255524,\n  'rmse': 0.5454821892441175,\n  'r2': 0.6683926912849316,\n  'euclidean_distance': 261.8314508371764},\n 'SVT': {'mae': 0.17825238352526018,\n  'mse': 0.08049457273010083,\n  'rmse': 0.2837156547145413,\n  'r2': 0.9102923368236316,\n  'euclidean_distance': 136.18351426297986},\n 'TimesNet': {'mae': 0.534439375265742,\n  'mse': 0.5310527978483749,\n  'rmse': 0.7287336947392887,\n  'r2': 0.4081649991734746,\n  'euclidean_distance': 349.79217347485866},\n 'Ensemble_Model': {'mae': 0.14089275544057492,\n  'mse': 0.04989781316643831,\n  'rmse': 0.2233781841775027,\n  'r2': 0.9443910804796616,\n  'euclidean_distance': 107.2215284052013}}"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model, metrics = tsi.train_ensemble(ground_truth = df_input, \n",
    "                                    algorithms=algorithms,\n",
    "                                    params=params, \n",
    "                                    train_params=train_params,\n",
    "                                    dimension_column=dimension_column, \n",
    "                                    datetime_format=datetime_format,\n",
    "                                    spatial_x_column=spatial_x_column, \n",
    "                                    spatial_y_column=spatial_y_column,\n",
    "                                    header=header, \n",
    "                                    sep=sep, \n",
    "                                    is_multivariate=is_multivariate, \n",
    "                                    areaVStime=areaVStime, \n",
    "                                    preprocessing=preprocessing, \n",
    "                                    index=index)\n",
    "metrics"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-18T12:58:37.253467Z",
     "start_time": "2024-04-18T12:58:18.481694Z"
    }
   },
   "id": "e8463e4866230439",
   "execution_count": 8
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Imputation with Ensemble Model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2d95313e789bb4fb"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "parameters = {\n",
    "    'dimension_column' : 'Dimension',\n",
    "    'datetime_format' : '%Y-%m-%d %H:%M:%S',\n",
    "    'spatial_x_column': 'Spatial_X',\n",
    "    'spatial_y_column' : 'Spatial_Y',\n",
    "    'sep' : ',',\n",
    "    'header' : 0,\n",
    "    'is_multivariate': False,\n",
    "    'areaVStime': 0,\n",
    "    'preprocessing': True,\n",
    "    'index': False,\n",
    "    \"algorithms\": [\"SoftImpute\", \"IterativeSVD\", \"SVT\", \"TimesNet\"],\n",
    "    \"params\": { \n",
    "        \"SoftImpute\": { \"max_rank\": 5 },\n",
    "        \"IterativeSVD\": { \"rank\": 3 }, \n",
    "        \"SVT\": { \"tauScale\": 0.7}, \n",
    "        \"TimesNet\":{ \n",
    "            \"n_layers\": 2, \"top_k\": 3, \n",
    "            \"d_model\":56, \"d_ffn\":56, \n",
    "            \"n_kernels\":1, \"dropout\":0.05, \n",
    "            \"apply_nonstationary_norm\": False,\n",
    "            \"batch_size\": 32,\n",
    "            \"epochs\":50,\n",
    "            \"num_workers\": 0                                                        \n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "dimension_column = parameters['dimension_column']\n",
    "header = parameters['header']\n",
    "sep = parameters['sep']\n",
    "spatial_x_column = parameters['spatial_x_column']\n",
    "spatial_y_column = parameters['spatial_y_column']\n",
    "datetime_format = parameters['datetime_format']\n",
    "is_multivariate = parameters['is_multivariate']\n",
    "areaVStime = parameters['areaVStime']\n",
    "preprocessing = parameters['preprocessing']\n",
    "index = parameters['index']\n",
    "algorithms = parameters['algorithms']\n",
    "params = parameters['params']"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-18T12:58:37.259293Z",
     "start_time": "2024-04-18T12:58:37.255247Z"
    }
   },
   "id": "7316c22364f48853",
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "freeing copy memory @ 0x1cf2aba0\n",
      "freeing copy memory @ 0x1c6c2040\n",
      "freeing copy memory @ 0x1c6c2040\n",
      "2024-04-18 15:58:43 [INFO]: No given device, using default device: cuda\n",
      "2024-04-18 15:58:43 [WARNING]: ‼️ saving_path not given. Model files and tensorboard file will not be saved.\n",
      "2024-04-18 15:58:43 [INFO]: TimesNet initialized with the given hyperparameters, the number of trainable parameters: 13,105\n",
      "2024-04-18 15:58:44 [INFO]: Epoch 001 - training loss: 0.4638\n",
      "2024-04-18 15:58:44 [INFO]: Epoch 002 - training loss: 0.3006\n",
      "2024-04-18 15:58:44 [INFO]: Epoch 003 - training loss: 0.2673\n",
      "2024-04-18 15:58:44 [INFO]: Epoch 004 - training loss: 0.2240\n",
      "2024-04-18 15:58:44 [INFO]: Epoch 005 - training loss: 0.1988\n",
      "2024-04-18 15:58:44 [INFO]: Epoch 006 - training loss: 0.1823\n",
      "2024-04-18 15:58:44 [INFO]: Epoch 007 - training loss: 0.1784\n",
      "2024-04-18 15:58:44 [INFO]: Epoch 008 - training loss: 0.1639\n",
      "2024-04-18 15:58:44 [INFO]: Epoch 009 - training loss: 0.1537\n",
      "2024-04-18 15:58:44 [INFO]: Epoch 010 - training loss: 0.1424\n",
      "2024-04-18 15:58:44 [INFO]: Epoch 011 - training loss: 0.1413\n",
      "2024-04-18 15:58:44 [INFO]: Epoch 012 - training loss: 0.1350\n",
      "2024-04-18 15:58:44 [INFO]: Epoch 013 - training loss: 0.1296\n",
      "2024-04-18 15:58:44 [INFO]: Epoch 014 - training loss: 0.1383\n",
      "2024-04-18 15:58:44 [INFO]: Epoch 015 - training loss: 0.1286\n",
      "2024-04-18 15:58:44 [INFO]: Epoch 016 - training loss: 0.1213\n",
      "2024-04-18 15:58:44 [INFO]: Epoch 017 - training loss: 0.1127\n",
      "2024-04-18 15:58:44 [INFO]: Epoch 018 - training loss: 0.1136\n",
      "2024-04-18 15:58:44 [INFO]: Epoch 019 - training loss: 0.1040\n",
      "2024-04-18 15:58:44 [INFO]: Epoch 020 - training loss: 0.1028\n",
      "2024-04-18 15:58:44 [INFO]: Epoch 021 - training loss: 0.1057\n",
      "2024-04-18 15:58:45 [INFO]: Epoch 022 - training loss: 0.1032\n",
      "2024-04-18 15:58:45 [INFO]: Epoch 023 - training loss: 0.0992\n",
      "2024-04-18 15:58:45 [INFO]: Epoch 024 - training loss: 0.1056\n",
      "2024-04-18 15:58:45 [INFO]: Epoch 025 - training loss: 0.0939\n",
      "2024-04-18 15:58:45 [INFO]: Epoch 026 - training loss: 0.0959\n",
      "2024-04-18 15:58:45 [INFO]: Epoch 027 - training loss: 0.0929\n",
      "2024-04-18 15:58:45 [INFO]: Epoch 028 - training loss: 0.0942\n",
      "2024-04-18 15:58:45 [INFO]: Epoch 029 - training loss: 0.0918\n",
      "2024-04-18 15:58:45 [INFO]: Epoch 030 - training loss: 0.0822\n",
      "2024-04-18 15:58:45 [INFO]: Epoch 031 - training loss: 0.0828\n",
      "2024-04-18 15:58:45 [INFO]: Epoch 032 - training loss: 0.0964\n",
      "2024-04-18 15:58:45 [INFO]: Epoch 033 - training loss: 0.0851\n",
      "2024-04-18 15:58:45 [INFO]: Epoch 034 - training loss: 0.0833\n",
      "2024-04-18 15:58:45 [INFO]: Epoch 035 - training loss: 0.0865\n",
      "2024-04-18 15:58:45 [INFO]: Epoch 036 - training loss: 0.0829\n",
      "2024-04-18 15:58:45 [INFO]: Epoch 037 - training loss: 0.0750\n",
      "2024-04-18 15:58:45 [INFO]: Epoch 038 - training loss: 0.0789\n",
      "2024-04-18 15:58:45 [INFO]: Epoch 039 - training loss: 0.0777\n",
      "2024-04-18 15:58:45 [INFO]: Epoch 040 - training loss: 0.0780\n",
      "2024-04-18 15:58:45 [INFO]: Epoch 041 - training loss: 0.0776\n",
      "2024-04-18 15:58:45 [INFO]: Epoch 042 - training loss: 0.0780\n",
      "2024-04-18 15:58:45 [INFO]: Epoch 043 - training loss: 0.0723\n",
      "2024-04-18 15:58:45 [INFO]: Epoch 044 - training loss: 0.0784\n",
      "2024-04-18 15:58:45 [INFO]: Epoch 045 - training loss: 0.0853\n",
      "2024-04-18 15:58:45 [INFO]: Epoch 046 - training loss: 0.0753\n",
      "2024-04-18 15:58:46 [INFO]: Epoch 047 - training loss: 0.0750\n",
      "2024-04-18 15:58:46 [INFO]: Epoch 048 - training loss: 0.0825\n",
      "2024-04-18 15:58:46 [INFO]: Epoch 049 - training loss: 0.0796\n",
      "2024-04-18 15:58:46 [INFO]: Epoch 050 - training loss: 0.0861\n",
      "2024-04-18 15:58:46 [INFO]: Finished training.\n"
     ]
    }
   ],
   "source": [
    "model_imputed_df = tsi.run_imputation_ensemble(missing = df_missing, \n",
    "                                               algorithms=algorithms,\n",
    "                                               params=params, \n",
    "                                               model=model,\n",
    "                                               dimension_column=dimension_column,\n",
    "                                               datetime_format=datetime_format,\n",
    "                                               spatial_x_column=spatial_x_column,\n",
    "                                               spatial_y_column=spatial_y_column,\n",
    "                                               header=header, \n",
    "                                               sep=sep, \n",
    "                                               is_multivariate=is_multivariate, \n",
    "                                               areaVStime=areaVStime, \n",
    "                                               preprocessing=preprocessing,\n",
    "                                               index=index)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-18T12:58:46.357016Z",
     "start_time": "2024-04-18T12:58:37.260656Z"
    }
   },
   "id": "b2cf91b790d58cd6",
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values count: 0\n"
     ]
    },
    {
     "data": {
      "text/plain": "                            Dimension  Spatial_X  Spatial_Y  \\\n0                 3i Group PLC_035999         96          0   \n1                Admiral Group_036346         97          1   \n2           Anglo American PLC_035918         98          2   \n3              Antofagasta PLC_028149         99          3   \n4                Ashtead Group_028090        100          4   \n..                                ...        ...        ...   \n91                Unilever PLC_035922        187         91   \n92  United Utilities Group PLC_036341        188         92   \n93          Vodafone Group PLC_035943        189         93   \n94               Whitbread PLC_035895        190         94   \n95                     WPP PLC_035947        191         95   \n\n    2017-01-02 00:00:00  2017-01-03 00:00:00  2017-01-04 00:00:00  \\\n0             -0.356507            -0.274725            -0.320673   \n1             -1.347635            -1.189826            -1.325091   \n2             -1.294240            -1.286110            -1.365373   \n3             -2.295047            -2.136391            -2.120526   \n4             -1.199292            -1.136860            -1.155222   \n..                  ...                  ...                  ...   \n91            -2.869013            -2.931364            -2.886828   \n92             0.733771             0.710001             0.638689   \n93            -0.007477             0.100982             0.241340   \n94            -0.898946            -0.881773            -0.713477   \n95             1.592327             1.624480             1.578037   \n\n    2017-01-05 00:00:00  2017-01-06 00:00:00  2017-01-09 00:00:00  \\\n0             -0.326436            -1.283419            -1.887600   \n1             -1.336363            -1.313819            -1.121690   \n2             -1.355211            -1.395858            -1.316596   \n3             -2.035909            -2.094083            -1.988312   \n4             -1.122170            -1.155222            -1.188275   \n..                  ...                  ...                  ...   \n91            -2.845854            -2.863669            -2.683742   \n92             0.724263             0.695738             0.705247   \n93             0.400838             0.481651             0.337039   \n94            -0.469618            -0.332233            -0.593265   \n95             1.642343             1.678069             1.767384   \n\n    2017-01-10 00:00:00  ...  2018-12-18 00:00:00  2018-12-19 00:00:00  \\\n0             -2.004563  ...            -1.356960            -1.273239   \n1             -1.223969  ...             0.129009             0.151553   \n2             -0.979221  ...             0.951131             1.116160   \n3             -1.787348  ...            -1.290226            -1.120993   \n4             -1.122170  ...            -0.920183            -0.918347   \n..                  ...  ...                  ...                  ...   \n91            -2.717589  ...             0.399962             0.417777   \n92             0.633935  ...            -0.762826            -0.705777   \n93             0.434864  ...            -1.793430            -1.725377   \n94             0.045575  ...             1.405687             1.467510   \n95             1.813828  ...            -1.785209            -1.708041   \n\n    2018-12-20 00:00:00  2018-12-21 00:00:00  2018-12-24 00:00:00  \\\n0             -1.297863            -1.098411            -1.509627   \n1              0.326270             0.343178             0.405175   \n2              0.913735             1.110469             1.060066   \n3             -1.427728            -1.300803            -1.271187   \n4             -1.098299            -1.120334            -0.967925   \n..                  ...                  ...                  ...   \n91             0.378584             0.373240             0.237849   \n92            -0.606891            -0.519415            -0.878827   \n93            -1.704111            -1.841067            -1.936340   \n94             1.481249             1.453772             1.656414   \n95            -1.798785            -1.805216            -1.858805   \n\n    2018-12-25 00:00:00  2018-12-26 00:00:00  2018-12-27 00:00:00  \\\n0             -1.509627            -1.509627            -1.310175   \n1              0.405175             0.405175             0.433355   \n2              1.060066             1.060066             0.958448   \n3             -1.271187            -1.271187            -1.406574   \n4             -0.967925            -0.967925            -1.175421   \n..                  ...                  ...                  ...   \n91             0.237849             0.237849            -0.063217   \n92            -0.878827            -0.878827            -1.002434   \n93            -1.936340            -1.936340            -2.063088   \n94             1.656414             1.656414             1.501856   \n95            -1.858805            -1.858805            -1.929542   \n\n    2018-12-28 00:00:00  2018-12-31 00:00:00  \n0             -1.027002            -1.297863  \n1              0.861694             1.132225  \n2              1.121038             1.095023  \n3             -1.173878            -1.150609  \n4             -0.978943            -0.989960  \n..                  ...                  ...  \n91             0.097114             0.038326  \n92            -0.802761            -0.833187  \n93            -1.932938            -2.004393  \n94             1.766322             1.859057  \n95            -1.848087            -1.870951  \n\n[96 rows x 524 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Dimension</th>\n      <th>Spatial_X</th>\n      <th>Spatial_Y</th>\n      <th>2017-01-02 00:00:00</th>\n      <th>2017-01-03 00:00:00</th>\n      <th>2017-01-04 00:00:00</th>\n      <th>2017-01-05 00:00:00</th>\n      <th>2017-01-06 00:00:00</th>\n      <th>2017-01-09 00:00:00</th>\n      <th>2017-01-10 00:00:00</th>\n      <th>...</th>\n      <th>2018-12-18 00:00:00</th>\n      <th>2018-12-19 00:00:00</th>\n      <th>2018-12-20 00:00:00</th>\n      <th>2018-12-21 00:00:00</th>\n      <th>2018-12-24 00:00:00</th>\n      <th>2018-12-25 00:00:00</th>\n      <th>2018-12-26 00:00:00</th>\n      <th>2018-12-27 00:00:00</th>\n      <th>2018-12-28 00:00:00</th>\n      <th>2018-12-31 00:00:00</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>3i Group PLC_035999</td>\n      <td>96</td>\n      <td>0</td>\n      <td>-0.356507</td>\n      <td>-0.274725</td>\n      <td>-0.320673</td>\n      <td>-0.326436</td>\n      <td>-1.283419</td>\n      <td>-1.887600</td>\n      <td>-2.004563</td>\n      <td>...</td>\n      <td>-1.356960</td>\n      <td>-1.273239</td>\n      <td>-1.297863</td>\n      <td>-1.098411</td>\n      <td>-1.509627</td>\n      <td>-1.509627</td>\n      <td>-1.509627</td>\n      <td>-1.310175</td>\n      <td>-1.027002</td>\n      <td>-1.297863</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Admiral Group_036346</td>\n      <td>97</td>\n      <td>1</td>\n      <td>-1.347635</td>\n      <td>-1.189826</td>\n      <td>-1.325091</td>\n      <td>-1.336363</td>\n      <td>-1.313819</td>\n      <td>-1.121690</td>\n      <td>-1.223969</td>\n      <td>...</td>\n      <td>0.129009</td>\n      <td>0.151553</td>\n      <td>0.326270</td>\n      <td>0.343178</td>\n      <td>0.405175</td>\n      <td>0.405175</td>\n      <td>0.405175</td>\n      <td>0.433355</td>\n      <td>0.861694</td>\n      <td>1.132225</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Anglo American PLC_035918</td>\n      <td>98</td>\n      <td>2</td>\n      <td>-1.294240</td>\n      <td>-1.286110</td>\n      <td>-1.365373</td>\n      <td>-1.355211</td>\n      <td>-1.395858</td>\n      <td>-1.316596</td>\n      <td>-0.979221</td>\n      <td>...</td>\n      <td>0.951131</td>\n      <td>1.116160</td>\n      <td>0.913735</td>\n      <td>1.110469</td>\n      <td>1.060066</td>\n      <td>1.060066</td>\n      <td>1.060066</td>\n      <td>0.958448</td>\n      <td>1.121038</td>\n      <td>1.095023</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Antofagasta PLC_028149</td>\n      <td>99</td>\n      <td>3</td>\n      <td>-2.295047</td>\n      <td>-2.136391</td>\n      <td>-2.120526</td>\n      <td>-2.035909</td>\n      <td>-2.094083</td>\n      <td>-1.988312</td>\n      <td>-1.787348</td>\n      <td>...</td>\n      <td>-1.290226</td>\n      <td>-1.120993</td>\n      <td>-1.427728</td>\n      <td>-1.300803</td>\n      <td>-1.271187</td>\n      <td>-1.271187</td>\n      <td>-1.271187</td>\n      <td>-1.406574</td>\n      <td>-1.173878</td>\n      <td>-1.150609</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Ashtead Group_028090</td>\n      <td>100</td>\n      <td>4</td>\n      <td>-1.199292</td>\n      <td>-1.136860</td>\n      <td>-1.155222</td>\n      <td>-1.122170</td>\n      <td>-1.155222</td>\n      <td>-1.188275</td>\n      <td>-1.122170</td>\n      <td>...</td>\n      <td>-0.920183</td>\n      <td>-0.918347</td>\n      <td>-1.098299</td>\n      <td>-1.120334</td>\n      <td>-0.967925</td>\n      <td>-0.967925</td>\n      <td>-0.967925</td>\n      <td>-1.175421</td>\n      <td>-0.978943</td>\n      <td>-0.989960</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>91</th>\n      <td>Unilever PLC_035922</td>\n      <td>187</td>\n      <td>91</td>\n      <td>-2.869013</td>\n      <td>-2.931364</td>\n      <td>-2.886828</td>\n      <td>-2.845854</td>\n      <td>-2.863669</td>\n      <td>-2.683742</td>\n      <td>-2.717589</td>\n      <td>...</td>\n      <td>0.399962</td>\n      <td>0.417777</td>\n      <td>0.378584</td>\n      <td>0.373240</td>\n      <td>0.237849</td>\n      <td>0.237849</td>\n      <td>0.237849</td>\n      <td>-0.063217</td>\n      <td>0.097114</td>\n      <td>0.038326</td>\n    </tr>\n    <tr>\n      <th>92</th>\n      <td>United Utilities Group PLC_036341</td>\n      <td>188</td>\n      <td>92</td>\n      <td>0.733771</td>\n      <td>0.710001</td>\n      <td>0.638689</td>\n      <td>0.724263</td>\n      <td>0.695738</td>\n      <td>0.705247</td>\n      <td>0.633935</td>\n      <td>...</td>\n      <td>-0.762826</td>\n      <td>-0.705777</td>\n      <td>-0.606891</td>\n      <td>-0.519415</td>\n      <td>-0.878827</td>\n      <td>-0.878827</td>\n      <td>-0.878827</td>\n      <td>-1.002434</td>\n      <td>-0.802761</td>\n      <td>-0.833187</td>\n    </tr>\n    <tr>\n      <th>93</th>\n      <td>Vodafone Group PLC_035943</td>\n      <td>189</td>\n      <td>93</td>\n      <td>-0.007477</td>\n      <td>0.100982</td>\n      <td>0.241340</td>\n      <td>0.400838</td>\n      <td>0.481651</td>\n      <td>0.337039</td>\n      <td>0.434864</td>\n      <td>...</td>\n      <td>-1.793430</td>\n      <td>-1.725377</td>\n      <td>-1.704111</td>\n      <td>-1.841067</td>\n      <td>-1.936340</td>\n      <td>-1.936340</td>\n      <td>-1.936340</td>\n      <td>-2.063088</td>\n      <td>-1.932938</td>\n      <td>-2.004393</td>\n    </tr>\n    <tr>\n      <th>94</th>\n      <td>Whitbread PLC_035895</td>\n      <td>190</td>\n      <td>94</td>\n      <td>-0.898946</td>\n      <td>-0.881773</td>\n      <td>-0.713477</td>\n      <td>-0.469618</td>\n      <td>-0.332233</td>\n      <td>-0.593265</td>\n      <td>0.045575</td>\n      <td>...</td>\n      <td>1.405687</td>\n      <td>1.467510</td>\n      <td>1.481249</td>\n      <td>1.453772</td>\n      <td>1.656414</td>\n      <td>1.656414</td>\n      <td>1.656414</td>\n      <td>1.501856</td>\n      <td>1.766322</td>\n      <td>1.859057</td>\n    </tr>\n    <tr>\n      <th>95</th>\n      <td>WPP PLC_035947</td>\n      <td>191</td>\n      <td>95</td>\n      <td>1.592327</td>\n      <td>1.624480</td>\n      <td>1.578037</td>\n      <td>1.642343</td>\n      <td>1.678069</td>\n      <td>1.767384</td>\n      <td>1.813828</td>\n      <td>...</td>\n      <td>-1.785209</td>\n      <td>-1.708041</td>\n      <td>-1.798785</td>\n      <td>-1.805216</td>\n      <td>-1.858805</td>\n      <td>-1.858805</td>\n      <td>-1.858805</td>\n      <td>-1.929542</td>\n      <td>-1.848087</td>\n      <td>-1.870951</td>\n    </tr>\n  </tbody>\n</table>\n<p>96 rows × 524 columns</p>\n</div>"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing = model_imputed_df.isnull().sum().sum()\n",
    "print(f\"Missing values count: {missing}\")\n",
    "model_imputed_df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-18T12:58:57.056936Z",
     "start_time": "2024-04-18T12:58:57.042750Z"
    }
   },
   "id": "83aeb8e669ea512d",
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-18T12:58:46.374074Z",
     "start_time": "2024-04-18T12:58:46.372082Z"
    }
   },
   "id": "d74ee07920c98cfb",
   "execution_count": 11
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
